{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795860f2-eabf-40d1-954c-843dcf672a7d",
   "metadata": {},
   "source": [
    "# MGT-499 Statistics and Data Science - Individual Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a58faf4-db28-41c1-9e6d-ead96d328eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here what you need\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5761d-3238-4e69-951f-6fea4557ef41",
   "metadata": {},
   "source": [
    "This notebook contains the individual assignment for the class MGT-499 Statistics and Data Science. Important information:\n",
    "- **Content**: the assignment is divided in two main parts, namely data cleaning (2 datasets) and Exploratory Data Analysis, for a total of 13 main questions (see table of contents). Some of these main questions are divided in sub questions. In the first part, the questions are very specific, while in the second part they are more open.\n",
    "- **Deadline**: Tuesday 8th of November at 23:59. \n",
    "- **Final Output**: a Jupyter notebook, which we (teachers) can run. \n",
    "- **Answering the Questions**: you will find the questions in markdown cells below. Under each of these cells, you will find a cell / cells for answers. Type there your answer. For the answer to be correct, the cell with the answer must run without error (unless specified). You can use markdown cells for the answers that require text.\n",
    "- **Submission**: submit the assignment on Moodle, under [Individual Assignment](https://moodle.epfl.ch/mod/assign/view.php?id=1222846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43ccf-9ed6-44ea-8dd3-184cb9e7c499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Content\n",
    "- [Polity5 Dataset](#polity5)  \n",
    "    - [Question 1: Import the data and get a first glance](#question1)\n",
    "    - [Question 2: Select some variables](#question2)\n",
    "    - [Question 3: Missing Values](#question3)\n",
    "    - [Question 4: Check Polity2](#question4)\n",
    "- [Quality of Government (QOG) Environmental Indicators Dataset](#qog)  \n",
    "    - [Question 5: Import the data and do few fixes](#question5)\n",
    "    - [Question 6: Merge QOG and Polity5 ... first attempt](#question6)\n",
    "    - [Question 7: Merge QOG and Polity5 ... second attempt](#question7)\n",
    "    - [Question 8: Clean the merged dataframe](#question8)\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "    - [Question 9: Selecting the ingredients for the recipe (how I select the variables)](#question9)  \n",
    "    - [Question 10: Picking the right quantity of each ingredient (how I select my sample)](#question10)\n",
    "    - [Question 11: Tasting and preparing the ingredients (univariate analysis)](#question11)\n",
    "    - [Question 12: Cooking the ingredients together (bivariate analysis)](#question12)\n",
    "    - [Question 13: Tasting the new recipe (conclusion)](#question13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142f738-6239-4e12-9c65-fd27b4db73ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polity5 data <a class=\"anchor\" id=\"polity5\"></a>\n",
    "\n",
    "Polity5 is a widely used democracy scale. The raw data as well as the codebook are available [here](http://www.systemicpeace.org/inscrdata.html). For this assignment, we have modified a bit the original version, for example we have added the iso3 code for countries to make you save time. You can find the modified version [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903da7f-480e-4777-a4ef-9ab94b09e473",
   "metadata": {},
   "source": [
    "### Question 1: import the data and get a first glance <a class=\"anchor\" id=\"question1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f6829-6c8f-451a-9670-4d1c7a103c12",
   "metadata": {},
   "source": [
    "1a) Import the csv 'polity2_iso3.csv' (file provided in the link [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)) as a panda dataframe (ignore the warning message) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7e4014-e55c-4994-a633-61a8fdf1e855",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Answer 1a\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/RitaGhilardi/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:667\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    664\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    676\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:336\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    335\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    337\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:236\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Answer 1a\n",
    "url = \"https://raw.githubusercontent.com/RitaGhilardi/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv\"\n",
    "pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd738c61-10ca-4439-8bcf-20e6987e3e5f",
   "metadata": {},
   "source": [
    "1b) Display the first 10 rows **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10544e0c-33b5-4b90-ad68-4cfe8d6c40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6decfca-afb8-4c77-881c-8fb78d96e68d",
   "metadata": {},
   "source": [
    "1c) Display the data types of all the variables included in the data **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa768541-03f9-424a-a690-d6132298f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ee31a-7cc9-44d2-b7f8-242f6ee5ebfc",
   "metadata": {},
   "source": [
    "1d) By looking at your answer in 1c, what is the difference between the different types of variables? Why the type of some variables is defined as object? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97f628-71b6-4aac-9c9c-596773557131",
   "metadata": {},
   "source": [
    "Answer 1d:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfba84f-b897-4fcb-880d-9d8995045239",
   "metadata": {},
   "source": [
    "### Question 2. Select some variables <a class=\"anchor\" id=\"question2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9776a-26ed-4154-af73-0e2b337e9e74",
   "metadata": {},
   "source": [
    "2a) Create a subset dataframe that contains the variables 'iso3', 'country', 'year', 'polity2' and display it **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3bd0a39-386d-4397-93eb-8eb7e0415a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4883d-8f9e-4b1f-9ce4-c62267090287",
   "metadata": {},
   "source": [
    "2b) Display the type of the variable \"year\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0dc6b73-70d9-42c0-9cd1-716033325a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639b2d3-b5e6-40f3-93c9-6547bcdcb814",
   "metadata": {},
   "source": [
    "2c) Convert the variable \"year\" to string **(1 point)**\n",
    "<br>\n",
    "Hint: if you get a warning message of the type \"SettingWithCopyWarning\", it is because you did not subset the data in the right way. Go back to your class notes and check the different ways to subset a dataframe, and try again. If you do it correctly, you will not get the warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "914d8f60-9875-40be-9f78-0c7c2837a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0babf3-0e33-4e13-9289-523ecef5e004",
   "metadata": {},
   "source": [
    "### Question 3: Missing Values <a class=\"anchor\" id=\"question3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb19a0f-bd7c-4d9c-bdfa-05e55e4eb26f",
   "metadata": {},
   "source": [
    "3a) Subset the rows that have iso3 missing and display **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eb48bb3-a92a-4565-8a5c-f22f642f2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b352b-c860-4b2c-bca3-5437c2bbaf23",
   "metadata": {},
   "source": [
    "3b) Display the countries that have missing iso3. What can you tell by looking at them? Any similarities? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7e9760a-a4a6-4826-b377-49ff300662f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41b9a2-2c70-41c6-b891-95e01f2a74a5",
   "metadata": {},
   "source": [
    "3c) Display the countries with missing iso3 from 2011. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b408fff2-6493-4dff-9294-ef1c564315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9a6b6-2151-4c5e-8a8a-ea9810905642",
   "metadata": {},
   "source": [
    "3d) Display the rows for which the column \"country\" contains the word \"Serbia\". By looking at the result, can you tell what happened to Serbia in 2006? **(1 point)**\n",
    "<br>\n",
    "Hint: the most general way of doing this is to use a combination of re.search and list comprehension. To display the full subset, you can use print(df.to_string())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a953ca64-d67b-4c94-8df6-5077efa68814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd97b-0aaa-4bca-affb-22f3c0ca387c",
   "metadata": {},
   "source": [
    "3e) Write a function that does the operation in 4d and use it to display the subset that has the word \"sudan\" (all lower cap) in country. Then do the same for the word \"vietnam\" (all lower cap). **(1 point)**\n",
    "<br>\n",
    "Hint: options of functions can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3217b330-72ef-4d38-8a66-1849d12f7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a0adc-6104-4dff-baa4-cbc8259183b4",
   "metadata": {},
   "source": [
    "3f) Replace nan values in iso3 with correct iso3 for the 5 countries found in 3c from 2011 onwards, and display the subset with the fixed values to check that everything worked. **(1 point)**\n",
    "<br>\n",
    "Hint: the correct iso3 for these 5 countries are \"ETH\",\"MNE\",\"SRB\",\"SDN\",\"VNM\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72ab9532-5a03-46fe-9db7-170e8b087957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa210c-b46f-46ff-a8da-d72d95bff196",
   "metadata": {},
   "source": [
    "3g) Drop the remaining rows which have nan in \"iso3\" and display the new number of rows of the dataframe (how many are they?) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c2cea78-0af1-405f-aeed-41dfc8fee4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dc318-2264-4e42-8ca3-f1cf5b85fac5",
   "metadata": {},
   "source": [
    "### Question 4: Check Polity2 <a class=\"anchor\" id=\"question4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d643-6867-4c1c-93f9-c3c38fb9d454",
   "metadata": {},
   "source": [
    "4a) Display the first and last year included in the dataset **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57202c70-fe45-4f45-a29b-6a4761421972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4593d98-be9b-45b3-86df-82e613ee851b",
   "metadata": {},
   "source": [
    "4b) What do the values in \"polity2\" represent? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4ecc-c2e6-4150-bf91-86bc067fd4a7",
   "metadata": {},
   "source": [
    "Answer 4b: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a9072-8271-4336-9219-3c64a3f16e07",
   "metadata": {},
   "source": [
    "4c) Do we have weird values for polity2? If yes, why? What should we do about them? Transform the data accordingly. **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e710121-c355-4f34-8f81-187ccee789b7",
   "metadata": {},
   "source": [
    "Answer 4c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef40f8d3-e7bd-49b9-9faa-a76931d0f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b6f3a-11d9-477f-9fab-f7e644176c67",
   "metadata": {},
   "source": [
    "4d) Make a map that shows the number of observations of polity2 by country **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53846332-57ef-4909-8367-5ffd2d737eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5258b-9ef6-4e9d-bf52-29a0d7ebc9b7",
   "metadata": {},
   "source": [
    "4e) Store the final dataframe (the one you obtained after 5d) in an object called df_pol **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bb74cbc-5356-4e4b-b5b4-a5174c9ced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b6cd3-101d-4343-b76d-d97583fe33ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality of Government Environmental Indicators <a class=\"anchor\" id=\"qog\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58204e-f401-4b6e-b64a-c9d098faa0f2",
   "metadata": {},
   "source": [
    "The QoG Environmental Indicators dataset (QoG-EI) (Povitkina, Marina, Natalia Alvarado Pachon & Cem Mert Dalli. 2021). The Quality of Government Environmental Indicators Dataset, version Sep21. University of Gothenburg: The Quality of Government Institute, https://www.gu.se/en/quality-government), is a compilation of indicators measuring countries' environmental performance over time, including the presence and stringency of environmental policies, environmental outcomes (emissions, deforestation, etc.), and public opinion on the environment. Codebook and data are available [here](https://www.gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc77f2-25d1-41ce-930a-c25a05ac9cdc",
   "metadata": {},
   "source": [
    "### Question 5: Import the data and do few fixes <a class=\"anchor\" id=\"question5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959796a-3340-4231-838c-a4e2cba4262c",
   "metadata": {},
   "source": [
    "5a) Import data from the Quality of Government Environmental Indicators Dataset and display the variables types and the number of rows **(1 point)**\n",
    "<br>\n",
    "Hint: When you go on the webpage of the Environmental Indicators Dataset, you can directly import from a URL by copying the link address of the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "501ef767-dca9-426e-9e34-1335038b3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a8293-d098-4a79-a803-50d52f6b63b3",
   "metadata": {},
   "source": [
    "5b) Rename the variable \"ccodealp\" to \"iso3\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc0e78d3-06b3-418c-81b8-05bbef009ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b34e8-0daa-4481-9b1b-61e7d318c571",
   "metadata": {},
   "source": [
    "5c) Check the type of the variables \"year\" and \"iso3\" are string, if not convert them to string **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1993423-8edf-4bb0-8ea0-69034fce5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b61d4-55aa-439b-823f-67aad3f6fc16",
   "metadata": {},
   "source": [
    "### Question 6: Merge QOG and Polity5 ... issues with QOG? <a class=\"anchor\" id=\"question6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8af7f-3b38-4834-90b4-e1cbbb7b7359",
   "metadata": {},
   "source": [
    "6a) Get a subset of the dataframe that includes the variables \"cname\", \"iso3\", \"year\" and \"cckp_temp\", and display the number of rows. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8736cd36-ed4e-4dbd-96a9-c3d51bd343be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a0373-fab5-4346-bed7-3500ed9aced0",
   "metadata": {},
   "source": [
    "6b) Merge this subset (left) and the clean version of the polity data (right), using the argument how=\"left\". Was the merge succesfull? If yes, how many rows has the merged dataframe? Is it the same number of rows of the subset in 6a? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bb2b0ba-fdd7-474a-9241-6d96e6eca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e5a50-5bda-4331-82a9-9cfe09a365cb",
   "metadata": {},
   "source": [
    "6c) Do the same by adding the argument validate=\"one-to-one\". Can you make some hypotheses on why you get an error? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fee8e0a9-75e7-4c37-80ad-3f5ddef8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8da9ac-de08-460e-b364-40aaf5a9aa34",
   "metadata": {},
   "source": [
    "6d) Consider the subset of the QOG you obtained in 6a and write a code to (i) count the number of observations for the variable \"cckp_temp\" for each combination of iso3 and year, (ii) store the results in a dataframe. For example, the combination \"USA-2012\" should have 1 observation for \"cckp_temp\", so the result of your code should be 1. The code should do this for all iso3-year combinations of your subset dataframe, and store the results in a dataframe. **(1 point)**\n",
    "<br>\n",
    "Hint: it should not take you more than 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "593a4be8-0760-454d-8f55-e5e0bd18af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e92628-2085-4edf-aed4-8e6db647d9c6",
   "metadata": {},
   "source": [
    "6e) Use the code in 6d to write a function that displays all rows of the dataframe obtained in 6a that have more than one observation of \"cckp_temp\" for each iso3-year combination, and check if it works. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e953896a-28a5-4d38-8ad3-93027c5c4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190da03-b34c-4566-8aec-5a1a540ac660",
   "metadata": {},
   "source": [
    "6f) Which countries have more than one observation for each iso3-year combination? Deal with these countries in the subset dataframe created in 6a to make sure you no longer have double observations for iso3-year combinations, and check that after your fix this is actually the case. **(1 point)**\n",
    "<br>\n",
    "Hint: should we keep a country with all missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d960c4a-b755-448c-8952-aee2e6eee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae70541-6427-4f83-bd05-37ef68baf5cd",
   "metadata": {},
   "source": [
    "6g) If your check went well, now you can perform the same operation directly in the QOG dataframe (not in the substed dataframe created in 6a). How many rows does now the QOG dataframe has? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c9f20b2-04e4-46d0-94f6-e580913ddfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd12e1-799e-4e4c-8d13-db496fb5bab4",
   "metadata": {},
   "source": [
    "### Question 7: Merge QOG and Polity5 ... issues with Polity5? <a class=\"anchor\" id=\"question7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72692a86-a9ab-44bb-bb56-b3c22e0829c4",
   "metadata": {},
   "source": [
    "7a) Merge the cleaned QOG dataframe (left) and the Polity dataframe (right) using the options how=\"left\" and validate=\"one_to_one\". Does it work? Why? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82261ca5-c3ec-49f6-8de8-be1b14943cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95740ccf-88d7-46ee-82ab-f1a8b42d9722",
   "metadata": {},
   "source": [
    "7b) Use the function you wrote in 6e to check what's wrong in the \"clean\" version of Polity **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "356409a0-73e8-41ac-af75-c2f6a462c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d8f5b-10f5-4540-b714-99b77f3e5203",
   "metadata": {},
   "source": [
    "7c) Drop or fix the countries that create troubles directly in the \"clean\" version of Polity and motivate your choices. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8aeb945c-418a-4eee-bdd3-2dce12246196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88282d66-3aa1-4fa4-b7cc-b448c649052c",
   "metadata": {},
   "source": [
    "7d) Try now to merge the \"clean-clean\" versions of COG and Polity (the ones you obtained in 7g and 8c) always using the options how=\"left\" and validate=\"one_to_one\". Does it work, and why? How many rows has the resulting merged dataframe? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12e52b0f-7484-4656-82bd-8de4cee284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8479c-556a-4c9b-b89f-a8f714e888ad",
   "metadata": {},
   "source": [
    "### Question 8: Clean the merged dataframe <a class=\"anchor\" id=\"question8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936854f-7882-47bc-a2c0-cb39b53128b0",
   "metadata": {},
   "source": [
    "8a) In the merged dataframe, order the columns so that you have the \"index\" variables first and the variables with actual values last. **(1 point)**\n",
    "<br>\n",
    "Hint: index variables are \"iso3\", \"year\" and other similar variables you can find, and the variables with actual values are \"polity2\", \"cckp_temp\" and other similar variables you can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7e92ad2-8007-4a4b-a47f-44c040ccfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39c4e8-6f99-47c9-9d32-4196e4184537",
   "metadata": {},
   "source": [
    "8b) Rename \"cname\" as \"country\" and \"country\" as \"country_polity\". **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89e2cccd-473d-462e-9b2f-726aa6763d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353db63e-08d7-41df-9bdf-e0aa20174569",
   "metadata": {},
   "source": [
    "8c) Save the clean merged dataframe as a csv in a subfolder called \"clean_data\" in your working directory **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a684c82-6df7-480f-9374-a2d4e7ec069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2840-c690-4b3e-8e4c-0025101bdc62",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa01e2b-dc8a-49ae-a19b-8c42bd0f2e57",
   "metadata": {},
   "source": [
    "In this section you will define a research question and perform a preliminary Exploratory Data Analysis (EDA) to address - or better, start addressing - the question at hand. This exercise will be done along the lines of the analysis done by our own Quentin Gallea in \"*A recipe to empirically answer any question quickly*\" ([Towards Data Science, 2022](https://towardsdatascience.com/a-recipe-to-empirically-answer-any-question-quickly-22e48c867dd5)). In this article, Quentin shows the first steps of an EDA that aims to explore whether heat waves have pushed governments to implement regulations against climate change (causal link). The logic is that, as it gets hotter and hotter, governments become more aware of climate change, and the problems it can cause to society, and start addressing it. In Quentin's analysis, heat waves (proxied by temperature) is the \"main explanatory variable\", rainfall is the \"explanatory variable for heterogeneity\", and regulations against climate change (proxied by the Environmental Policy Stringency Index) is the \"outcome variable\". He finds that indeed countries with relatively high temperatures have implemented more regulations against climate change. This is true especially when rainfall levels are low, as when it does not rain the damage of extreme heat is more evident to legislators, who therefore apply stricter regulations against these phenomenons.\n",
    "<br>\n",
    "<br>\n",
    "In this exercise, you will be asked to do a similar analysis on a research question of your choice, using at least two of the variables of the dataset we have created in the former questions (QOG + Polity). For example, \"what is the average temperature in 2010?\" is not a valid research question (univariate), while \"what is the impact of high temperatures on the stringency of climate regulations?\" is a valid research question (at least bivariate). As before, we will ask you some (this time more general and open) questions, and you should report your answer in the cells below each question. Use a mix of markdown and code cells to answer (markdown for text and code for graphs and tables). We should be able to run all the graphs, i.e. screenshots of graphs are not accepted. Note that for now we have put only one markdown cell and one code cell for the answer, but feel free to add as many cells as you need.\n",
    "<br>\n",
    "Beyond the python code, we will grade the interpretations of the results and the coding decision you make.\n",
    "<br>\n",
    "<br>\n",
    "Let your creativity guide you and let's have some fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97f39-3b6d-4546-8871-b136d122854c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 9: Selecting the ingredients (how I select the variables) <a class=\"anchor\" id=\"question9\"></a>\n",
    "We have saved the clean merged data that resulted from the previous questions in \"clean_data_prepared_EDA\" (it should be the same of the one you saved in \"clean_data\"). Import the clean merged data from \"clean_data_prepared_EDA\" using this [link](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/clean_data_prepared_EDA/df_qog_polity_merged.csv). Explore the variables in the newly obtained dataframe by checking the documentation of QOG and Polity. Then, define a research question that addresses a causal link between at least two of these variables. Describe the research question, why you are addressing it and the variables of interest (outcome variable, main explanatory variable and explanatory variable for heterogeneity). **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df577a5-f0f1-43e8-aeb1-0708fe53892b",
   "metadata": {},
   "source": [
    "Answer 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575ca1f-de5a-4b03-a51a-7f0cc5fa18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b5531-0329-4817-a341-d1a1bb96ef2d",
   "metadata": {},
   "source": [
    "### Question 10: Picking the right quantity of each ingredient (how I select my sample) <a class=\"anchor\" id=\"question10\"></a>\n",
    "Explore the data availability of your variables of interest and select a clean sample for the analysis. Describe this sample with the help of summary-statistics tables and maps. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef40ba-ff3a-4983-99c7-151be2f9622e",
   "metadata": {},
   "source": [
    "Answer 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb262470-32d1-4d2c-af1c-8616daed69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4434c1-4ca5-44af-a24c-67a1b8d20cc6",
   "metadata": {},
   "source": [
    "### Question 11: Tasting and preparing the ingredients (univariate analysis) <a class=\"anchor\" id=\"question11\"></a>\n",
    "Do an univariate analysis for each variable you have chosen (outcome variable, main explanatory variable and explanatory variable for heterogeneity):\n",
    "- Prepare the variable, for example see if you need to transform the data further, i.e. log-transform, define a categorical variable, deal with outliers, etc.\n",
    "- Understand the nature of the variable, i.e. continuous, categorical, binary, etc., which then allows to pick the right statistical tool in the bivariate analysis.\n",
    "- Get an idea of the variable's behaviour across time and space.\n",
    "\n",
    "Describe these steps and the conclusions you can draw with the help of histograms, tables, maps and line graphs. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef687c9b-69c5-49b0-adb3-2aac7406112c",
   "metadata": {},
   "source": [
    "Answer 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fffac2-d33c-410f-9f10-c190a4c59641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ad4a-70fc-4f39-bffb-cf10dd93205f",
   "metadata": {},
   "source": [
    "### Question 12: Cooking the ingredients together (bivariate analysis) <a class=\"anchor\" id=\"question12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c658-8c22-4bb0-b1ef-4b5860f6cc31",
   "metadata": {},
   "source": [
    "Considering the \"nature\" of your variables (continuous, categorical, binary, etc.), pick the right tool / tools for a preliminary bivariate analysis, i.e. correlation tables, bar/line graphs, scatter plots, etc. Use these tools to describe your preliminary bivariate analysis and your findings. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bb04c-9223-4e3d-b815-2d7ee3657f00",
   "metadata": {},
   "source": [
    "Answer 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c0962-c661-4649-b8f3-e721e7ef66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 12:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0a05d-004a-42f3-b472-b7a808cd0dc1",
   "metadata": {},
   "source": [
    "### Question 13: Tasting the new recipe (conclusion) <a class=\"anchor\" id=\"question13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b861d-d4d5-42b1-94ad-5aa33f9bf7a2",
   "metadata": {},
   "source": [
    "Explain what you learned, the problem faced, what would you do next (you can suggest other data you would like to have etc). **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536aef2-a8df-4e17-9089-01ba8d93c029",
   "metadata": {},
   "source": [
    "Answer 13:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
